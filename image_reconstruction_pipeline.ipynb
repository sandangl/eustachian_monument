{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78517d26",
   "metadata": {},
   "source": [
    "# Image Stereoscopic Reconstruction (Pipeline)\n",
    "\n",
    "In this notebook, we explore the process of image translation, in order to obtain a frontal view of an architectural object from the corresponding lateral view, with possible image enhancements (inclusion of new details, inpainting, etc.).\n",
    "To achieve this, we are going to use an attention based, Chain of Thoughts (CoT) driven generative process, which includes an LLM coupled with a Conditional Latent Diffusion Model (in our example, we are using Omnigen)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf4a96",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f7c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import ollama\n",
    "import chromadb\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befed00",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path) -> str:\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "def decode_and_show_image(base64_img, img_format: str):\n",
    "    decoded_bytes = io.BytesIO(base64.b64decode(base64_img))\n",
    "    decoded_image = mpimg.imread(decoded_bytes, format=img_format)\n",
    "    \n",
    "    plt.imshow(decoded_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a608590f",
   "metadata": {},
   "source": [
    "### Ollama\n",
    "\n",
    "We make use of [Ollama](), a local LLM orchestrator.\n",
    "Feel free to experiment with other vision models of your taste ([list of available ones](https://ollama.com/search?c=vision))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434\"   # Feel free to change if your Ollama port is different\n",
    "MODEL = \"qwen2.5vl:32b\"                 # Our approach is tested with and works best with Qwen2.5-VL 32B.\n",
    "\n",
    "%ollama pull $MODEL\n",
    "%ollama serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ee388",
   "metadata": {},
   "source": [
    "### Vector Store\n",
    "\n",
    "We make use of [ChromaDB](https://www.trychroma.com/), a lightweight and easy to set up in-memory vector store.\n",
    "Documentation can be found [here](https://docs.trychroma.com/docs/overview/getting-started)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f81d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.EphemeralClient()  #By default, we use an in-memory approach which does not persist anything for this demo.\n",
    "collection = chroma_client.create_collection(name=\"eustachian_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b111d",
   "metadata": {},
   "source": [
    "Adding two images to the vector store, for final image details enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ce783",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    ids=[\"id1\", \"id2\"],\n",
    "    documents=[\n",
    "        f\"\"\"\n",
    "        {{ \n",
    "            \"caption\": \"A statue of St. Eustace, patron saint of Matera, suited in armor with a golden plume, holding a spear upright in its right hand.\",\n",
    "            \"base64\": \"{encode_image('assets/stEustace.jpg')}\"\n",
    "        }}\n",
    "        \"\"\",\n",
    "        f\"\"\"\n",
    "        {{ \n",
    "            \"caption\": \"A statue of St. Vitus, suited in light armor and a red cape, bringing a silver cross in is left hand, followed by two dogs of the same breed, of brown and black.\",\n",
    "            \"base64\": \"{encode_image('assets/stVitus.jpg')}\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7383b",
   "metadata": {},
   "source": [
    "#### Example of querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"This is a query document about a saint followed by dogs\"],\n",
    "    n_results=1\n",
    ")\n",
    "print(json.loads(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb9ad8",
   "metadata": {},
   "source": [
    "## Phase 1: Prospective Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc837642",
   "metadata": {},
   "source": [
    "## Phase 2: Image RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d9473",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
